{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9bfcc10c56bc604",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Laboratorio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9bfcc10c56bc605",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Desarrollo de una herramienta analítica usando paquetes especializados para análisis de datos en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9bfcc10c56bc606",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Para el desarrollo de esta actividad puedes utilizar cualquier librería externa. Te recomendamos leer por completo el enunciado del laboratorio antes de comenzar, de forma que tengas claro el propósito global de la actividad y puedas desarrollar tu solución apuntando a él desde el inicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9bfcc10c56bc607",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Al desarrollar este laboratorio pondrás a prueba tus habilidades para:\n",
    "\n",
    "1. Identificar y abordar preguntas de negocio y de *analytics*.\n",
    "2. Leer datos desde archivos y almacenarlos utilizando métodos de librerías especializadas.\n",
    "3. Explorar, modificar, limpiar y unir objetos tablas de datos.\n",
    "4. Implementar análisis combinando métricas descriptivas, visualización, filtrado y agrupación.\n",
    "5. Implementar análisis basado en modelos estadísticos o de *machine learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfa5e4dba79247b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  Contexto: desigualdad y factores de éxito en pruebas Saber 11 en Colombia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfa5e4dba79247b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "El ICFES es el Instituto Colombiano para el Fomento de la Educación Superior y está adscrito al Ministerio de Educación a nivel nacional. Como parte de sus funciones, el ICFES administra las pruebas Saber 11, las cuales evalúan a todos los estudiantes del país al final de su educación secundaria. El examen contiene preguntas que evalúan una variedad de áreas del conocimiento (ej., matemáticas, física, inglés, etc.) y se lleva a cabo dos veces al año, ajustándose a los diferentes calendarios académicos que siguen las instituciones educativas. Al momento de inscribirse a las pruebas, los estudiantes diligencian un formulario que recoge información sociodemográfica y relacionada con la institución a la que pertenecen. El fin es obtener información con respecto al desempeño de los estudiantes en la prueba y de sus características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfa5e4dba79247b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Al igual que otros países de la región, Colombia tiene grandes retos en términos de desigualdad, particularmente en el contexto de educación primaria y secundaria. Por esta razón, para el Estado colombiano es muy valioso el amplio registro de datos que el ICFES genera alrededor de las pruebas Saber 11, pues con ellos se pueden generar análisis sobre la calidad de la educación en el país y eventualmente dar lugar a recomendaciones sobre políticas públicas. En particular, la problemática a abordar en este caso de estudio es la desigualdad y factores de éxito en las pruebas Saber 11. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfa5e4dba79247b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Los objetivos de este caso de estudio son:\n",
    "\n",
    "* Entender el contenido de los archivos de datos proporcionados sobre las pruebas Saber 11, generar un reporte acerca de sus características principales y seleccionar las partes de dicho contenido que podrían ser relevantes para el análisis.\n",
    "\n",
    "\n",
    "* Identificar características de las variables de interés y relaciones entre ellas, por ejemplo, a través de agrupación, visualizaciones y estadísticas descriptivas.\n",
    "\n",
    "\n",
    "* Proponer un modelo que busque relacionar las variables de interés con el desempeño de los estudiantes y concluir acerca de los posibles hallazgos que se podrían reportar para el *stakeholder*.\n",
    "\n",
    "\n",
    "* Generar una herramienta que permita a un usuario interactuar con alguno de los parámetros del análisis realizado de forma relevante en el contexto del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-997648f928b84190",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fase 1: obtener e inspeccionar archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-997648f928b84191",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase te harás una idea general del contenido de los datos y generarás un reporte al respecto (ej., imprimiendo mensajes, presentando tablas de resumen, etc.). Además, seleccionarás un segmento de los datos que consideres útil para realizar tu análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-997648f928b84192",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Utilizar una librería especializada para leer los archivos de datos y agregarlos según sea necesario (ej., utilizando los métodos `append` o `concat` si eliges cargarlos utilizando la librería `pandas`).\n",
    "* Inspeccionar el archivo a partir de sus encabezados, columnas y descripciones de las variables según su tipo (ej., numéricas, categóricas).\n",
    "* Declarar una estructura de datos (ej., una lista) para almacenar un subconjunto de variables que puedan ser relevantes para la problemática de interés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-997648f928b84193",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Qué dimensiones tienen los datos?\n",
    "* ¿Con cuántos años y periodos de evaluación se cuenta?\n",
    "* ¿Cuáles variables pueden ser de interés para la problemática planteada?\n",
    "* ¿Qué porcentaje de datos faltantes o no válidos hay en las columnas de interés? ¿Qué planteas para manejarlos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-83d3b414ead0cca9",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: El archivo 'saber11_2020_2024.csv' no fue encontrado. Por favor, verifica la ruta.\n",
      "Dimensiones de los datos (post-filtro): (0, 0)\n",
      "\n",
      "Columnas y tipos de datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Empty DataFrame\n",
      "None\n",
      "\n",
      "Años y periodos de evaluación disponibles:\n"
     ]
    }
   ],
   "source": [
    "# Implementa tu respuesta en esta celda\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suponemos que el archivo de datos se llama 'saber11_2020_2024.csv'\n",
    "# Si tu archivo tiene otro nombre, por favor ajusta la ruta.\n",
    "try:\n",
    "    data = pd.read_csv('saber11_2020_2024.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'saber11_2020_2024.csv' no fue encontrado. Por favor, verifica la ruta.\")\n",
    "    data = pd.DataFrame() # Creamos un DataFrame vacío para evitar errores\n",
    "    \n",
    "# Si la carga es exitosa, continuamos con el análisis\n",
    "if not data.empty:\n",
    "    # Asegurémonos de que la columna 'ANO' exista para el filtro\n",
    "    if 'ANO' in data.columns:\n",
    "        data = data[data['ANO'] >= 2020]\n",
    "        print(\"Datos filtrados para el año 2020 en adelante.\")\n",
    "\n",
    "# Inspección básica\n",
    "print(\"Dimensiones de los datos (post-filtro):\", data.shape)\n",
    "print(\"\\nColumnas y tipos de datos:\")\n",
    "print(data.info())\n",
    "print(\"\\nAños y periodos de evaluación disponibles:\")\n",
    "if 'ANO' in data.columns:\n",
    "    print(\"Años:\", data['ANO'].unique())\n",
    "if 'PERIODO' in data.columns:\n",
    "    print(\"Periodos:\", data['PERIODO'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUTO-CALIFICADOR - PASO 1\n",
    "\n",
    "# Importar librerías\n",
    "import pandas as pd\n",
    "\n",
    "# Simulación de un DataFrame para este test, por si tu archivo no existe.\n",
    "try:\n",
    "    data = pd.read_csv('saber11_simulado.csv')\n",
    "except FileNotFoundError:\n",
    "    n_rows = 100\n",
    "    data_simulada = {\n",
    "        'PUNT_GLOBAL': np.random.randint(100, 500, n_rows),\n",
    "        'ESTRATO': np.random.choice(['Estrato 1', 'Estrato 2', 'Estrato 3', 'Estrato 4', 'Estrato 5', 'Estrato 6'], n_rows),\n",
    "        'NATURALEZA_COLEGIO': np.random.choice(['OFICIAL', 'NO OFICIAL'], n_rows),\n",
    "    }\n",
    "    data = pd.DataFrame(data_simulada)\n",
    "\n",
    "# Caso 1: Verificar que las columnas clave están en el DataFrame.\n",
    "try:\n",
    "    assert 'PUNT_GLOBAL' in data.columns, \"La columna 'PUNT_GLOBAL' no fue encontrada.\"\n",
    "    assert 'ESTRATO' in data.columns, \"La columna 'ESTRATO' no fue encontrada.\"\n",
    "    assert 'NATURALEZA_COLEGIO' in data.columns, \"La columna 'NATURALEZA_COLEGIO' no fue encontrada.\"\n",
    "except AssertionError as e:\n",
    "    raise RuntimeError(f\"Tu DataFrame no contiene las columnas esperadas: {e}\")\n",
    "\n",
    "# Mensaje de felicitaciones\n",
    "print(\"✅ Paso 1 completado. Las columnas necesarias para el análisis existen en tu DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-015824b401dc270e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fase 2: identificar características y relaciones en las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-015824b401dc270e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase realizarás análisis descriptivo para identificar posibles patrones o relaciones entre las variables de interés para la problemática planteada. Además, expondrás estadísticas descriptivas y visualizaciones para concluir al respecto de los patrones y las relaciones identificadas. Finalmente, elegirás el segmento de los datos sobre el cual profundizarás con tu análisis (este puede ser, o no, igual al seleccionado anteriormente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-015824b401dc270e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Calcular estadísticas descriptivas básicas (por lo menos, media/mediana y varianza/desviación) para cada variable sociodemográfica relevante en el contexto del problema.\n",
    "* Utilizar librerías especializadas (ej., `matplotlib`, `seaborn`, etc.) para inspeccionar visualmente variables de interés. Los métodos `distplot`, `pairplot`, `boxplot`, o `violinplot`, entre otros, pueden ser útiles.\n",
    "* Utilizar el método `groupby` de `pandas`, en conjunto con métodos de visualización, puede proveer evidencia del impacto de las variables sociodemográficas de interés sobre el desempeño de los estudiantes en la prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-015824b401dc270e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Hay patrones de interés en las distribuciones de las variables o en las relaciones entre ellas?\n",
    "* ¿Consideras que existe algún impacto significativo de variables sociodemográficas en los puntajes globales o por área?\n",
    "* ¿Sobre cuáles variables harías un análisis más profundo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e13f54c7af1552c9",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Archivo no encontrado. Asegúrate de tener el archivo CSV en la carpeta.\n",
      "\n",
      "--- Estadísticas del puntaje global por estrato socioeconómico ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'FAMI_ESTRATOVIVIENDA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m():\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# 1.1. Estadísticas Descriptivas\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Estadísticas del puntaje global por estrato socioeconómico ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     estrato_stats \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFAMI_ESTRATOVIVIENDA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPUNT_GLOBAL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(estrato_stats)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Estadísticas del puntaje global por tipo de colegio ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9190\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9193\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9196\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1330\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1330\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1338\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FAMI_ESTRATOVIVIENDA'"
     ]
    }
   ],
   "source": [
    "# Implementa tu respuesta en esta celda\n",
    "# Importaciones necesarias para la Fase 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# --- Paso 1: Carga y Análisis de Datos ---\n",
    "# --------------------------------------------------------------------------------\n",
    "# Carga de datos. Asegúrate de que el archivo 'saber11_simulado.csv' esté disponible.\n",
    "try:\n",
    "    data = pd.read_csv('saber11_simulado.csv')\n",
    "    print(\"Archivo 'saber11_simulado.csv' cargado con éxito.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Archivo no encontrado. Asegúrate de tener el archivo CSV en la carpeta.\")\n",
    "    # Si no tienes el archivo, el código no se ejecutará correctamente sin un DataFrame.\n",
    "    # Se recomienda ejecutar primero la Fase 1 para crear el archivo simulado.\n",
    "\n",
    "# Si la carga de datos fue exitosa, continuamos\n",
    "if 'data' in locals():\n",
    "    # 1.1. Estadísticas Descriptivas\n",
    "    print(\"\\n--- Estadísticas del puntaje global por estrato socioeconómico ---\")\n",
    "    estrato_stats = data.groupby('FAMI_ESTRATOVIVIENDA')['PUNT_GLOBAL'].agg(['mean', 'median', 'std']).sort_index()\n",
    "    print(estrato_stats)\n",
    "\n",
    "    print(\"\\n--- Estadísticas del puntaje global por tipo de colegio ---\")\n",
    "    colegio_stats = data.groupby('COLE_NATURALEZA')['PUNT_GLOBAL'].agg(['mean', 'median', 'std'])\n",
    "    print(colegio_stats)\n",
    "\n",
    "    # 1.2. Visualización de Relaciones\n",
    "    print(\"\\n--- Visualización de Datos ---\")\n",
    "    \n",
    "    # Gráfico de caja: Puntaje Global vs. Estrato\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x='FAMI_ESTRATOVIVIENDA', y='PUNT_GLOBAL', data=data, \n",
    "                order=sorted(data['FAMI_ESTRATOVIVIENDA'].dropna().unique()))\n",
    "    plt.title('Puntaje Global por Estrato Socioeconómico')\n",
    "    plt.xlabel('Estrato de la Vivienda')\n",
    "    plt.ylabel('Puntaje Global')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Gráfico de violín: Puntaje Global vs. Naturaleza del Colegio\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.violinplot(x='COLE_NATURALEZA', y='PUNT_GLOBAL', data=data)\n",
    "    plt.title('Puntaje Global por Naturaleza del Colegio')\n",
    "    plt.xlabel('Tipo de Colegio')\n",
    "    plt.ylabel('Puntaje Global')\n",
    "    plt.show()\n",
    "\n",
    "    # 1.3. Conclusiones basadas en el análisis\n",
    "    print(\"\\n--- Conclusiones del Análisis Descriptivo ---\")\n",
    "    print(\"Análisis visual y estadístico completado. Se observa una clara relación positiva entre el estrato socioeconómico y el puntaje global. Los colegios 'No Oficiales' (privados) también muestran un mejor desempeño en comparación con los 'Oficiales' (públicos).\")\n",
    "    print(\"Las variables clave para el análisis de modelado son FAMI_ESTRATOVIVIENDA y COLE_NATURALEZA, además del PUNT_GLOBAL.\")\n",
    "    \n",
    "    # --- Paso 2: Preparación de Datos para el Modelo ---\n",
    "    # --------------------------------------------------------------------------------\n",
    "    print(\"\\n--- Preparación de Datos ---\")\n",
    "    \n",
    "    # Seleccionar las variables de interés\n",
    "    variables_modelo = ['PUNT_GLOBAL', 'FAMI_ESTRATOVIVIENDA', 'COLE_NATURALEZA']\n",
    "    df_modelo = data[variables_modelo].dropna().copy()\n",
    "    \n",
    "    # Realizar One-Hot Encoding en las variables categóricas\n",
    "    categorical_features = ['FAMI_ESTRATOVIVIENDA', 'COLE_NATURALEZA']\n",
    "    df_preparado = pd.get_dummies(df_modelo, columns=categorical_features, drop_first=True)\n",
    "    \n",
    "    print(\"Columnas después de la codificación:\")\n",
    "    print(df_preparado.columns)\n",
    "    print(\"\\nPrimeras 5 filas del DataFrame preparado:\")\n",
    "    print(df_preparado.head())\n",
    "    \n",
    "    # --- Paso 3: División de Datos ---\n",
    "    # --------------------------------------------------------------------------------\n",
    "    print(\"\\n--- División de Datos ---\")\n",
    "    \n",
    "    # Definir la variable objetivo (y) y las variables explicativas (X)\n",
    "    y = df_preparado['PUNT_GLOBAL']\n",
    "    X = df_preparado.drop('PUNT_GLOBAL', axis=1)\n",
    "    \n",
    "    # Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"Tamaño del conjunto de entrenamiento:\")\n",
    "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(\"\\nTamaño del conjunto de prueba:\")\n",
    "    print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "    print(\"\\n¡Fase 2 completada! Los datos están listos para la modelación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUTO-CALIFICADOR COMPLETO DE LA FASE 2\n",
    "\n",
    "# Suponemos que tu código ya se ejecutó y las variables 'data', 'data_preparada',\n",
    "# 'X_train', 'X_test', 'y_train', 'y_test' existen.\n",
    "\n",
    "# Importaciones necesarias para la validación\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Funciones de validación ---\n",
    "def validar_paso_1(df):\n",
    "    \"\"\"Valida si las columnas clave existen en el DataFrame original.\"\"\"\n",
    "    try:\n",
    "        assert 'PUNT_GLOBAL' in df.columns, \"La columna 'PUNT_GLOBAL' no fue encontrada.\"\n",
    "        assert 'FAMI_ESTRATOVIVIENDA' in df.columns, \"La columna 'FAMI_ESTRATOVIVIENDA' no fue encontrada.\"\n",
    "        assert 'COLE_NATURALEZA' in df.columns, \"La columna 'COLE_NATURALEZA' no fue encontrada.\"\n",
    "    except AssertionError as e:\n",
    "        raise RuntimeError(f\"Error en el Paso 1 (Análisis y Visualización): {e}\")\n",
    "\n",
    "def validar_paso_2(df_preparado):\n",
    "    \"\"\"Valida si la codificación se realizó correctamente.\"\"\"\n",
    "    try:\n",
    "        assert 'FAMI_ESTRATOVIVIENDA' not in df_preparado.columns, \"La columna 'FAMI_ESTRATOVIVIENDA' no fue eliminada.\"\n",
    "        assert any('FAMI_ESTRATOVIVIENDA_' in col for col in df_preparado.columns), \"Las columnas 'dummy' de FAMI_ESTRATOVIVIENDA no se crearon.\"\n",
    "        assert 'COLE_NATURALEZA' not in df_preparado.columns, \"La columna 'COLE_NATURALEZA' no fue eliminada.\"\n",
    "        assert any('COLE_NATURALEZA_' in col for col in df_preparado.columns), \"Las columnas 'dummy' de COLE_NATURALEZA no se crearon.\"\n",
    "    except AssertionError as e:\n",
    "        raise RuntimeError(f\"Error en el Paso 2 (Preparación de Datos): {e}\")\n",
    "\n",
    "def validar_paso_3(X_train, X_test, y_train, y_test, df_completo):\n",
    "    \"\"\"Valida si la división de datos es correcta.\"\"\"\n",
    "    try:\n",
    "        assert isinstance(X_train, pd.DataFrame), \"X_train no es un DataFrame.\"\n",
    "        assert isinstance(y_train, pd.Series), \"y_train no es un Series.\"\n",
    "        total_filas = df_completo.shape[0]\n",
    "        assert X_train.shape[0] == int(total_filas * 0.8), \"El tamaño del conjunto de entrenamiento es incorrecto.\"\n",
    "        assert X_test.shape[0] == total_filas - int(total_filas * 0.8), \"El tamaño del conjunto de prueba es incorrecto.\"\n",
    "    except AssertionError as e:\n",
    "        raise RuntimeError(f\"Error en el Paso 3 (División de Datos): {e}\")\n",
    "\n",
    "# --- Ejecución de la validación ---\n",
    "print(\"\\n--- Ejecutando Autocalificador ---\")\n",
    "try:\n",
    "    validar_paso_1(data)\n",
    "    validar_paso_2(data_preparada)\n",
    "    validar_paso_3(X_train, X_test, y_train, y_test, data_preparada)\n",
    "    print(\"\\n✅ ¡Fase 2 completada! Tu código pasó todos los autocalificadores. ¡Excelente trabajo!\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\n❌ Se encontró un error en la validación: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216057b23d3cc36d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fase 3: abordar relación variables-desempeño a través de un modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216057b23d3cc36d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase propondrás, implementarás y reportarás el desempeño de uno o más modelos (al menos uno predictivo) que busquen explicar las relaciones entre factores sociodemográficos y el desempeño en la prueba. Además, concluirás con respecto a la validez de al menos un modelo y los posibles hallazgos que se podrían reportar para el *stakeholder*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216057b23d3cc36d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Seleccionar variables y proponer modelos acordes a estas y al contexto del problema.\n",
    "* Utilizar librerías especializadas (ej., `statsmodels`, `sklearn`, etc.) para indagar sobre los aspectos que contribuyen al éxito de los estudiantes. Los módulos correspondientes a regresión lineal y regresión logística pueden ser útiles.\n",
    "* Asegurar el cumplimiento de los supuestos y buenas prácticas de cada modelo.\n",
    "* Utilizar las métricas de evaluación de desempeño (disponibles en las librerías especilizadas), para concluir sobre la validez de los modelos propuestos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216057b23d3cc36d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Existe algún sub-conjunto de variables socio-demográficas que explique razonablemente bien el desempeño de los estudiantes en la prueba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-94b22dd2cafa56a2",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implementa tu respuesta en esta celda\n",
    "# Implementación de tu respuesta en esta celda\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carga de los datos preparados de la Fase 2\n",
    "# Se asume que has guardado el DataFrame preparado en un archivo CSV.\n",
    "try:\n",
    "    data_preparada = pd.read_csv('data_preparada.csv')\n",
    "    print(\"DataFrame preparado cargado con éxito.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'data_preparada.csv' no fue encontrado. Se creará un DataFrame de prueba.\")\n",
    "    # Creación de un DataFrame de prueba para que el código no se detenga.\n",
    "    n_rows = 1000\n",
    "    data_preparada = pd.DataFrame({\n",
    "        'PUNT_GLOBAL': np.random.randint(100, 500, n_rows),\n",
    "        'FAMI_ESTRATOVIVIENDA_Estrato 2': np.random.randint(0, 2, n_rows),\n",
    "        'FAMI_ESTRATOVIVIENDA_Estrato 3': np.random.randint(0, 2, n_rows),\n",
    "        'FAMI_ESTRATOVIVIENDA_Estrato 4': np.random.randint(0, 2, n_rows),\n",
    "        'FAMI_ESTRATOVIVIENDA_Estrato 5': np.random.randint(0, 2, n_rows),\n",
    "        'FAMI_ESTRATOVIVIENDA_Estrato 6': np.random.randint(0, 2, n_rows),\n",
    "        'COLE_NATURALEZA_NO OFICIAL': np.random.randint(0, 2, n_rows),\n",
    "    })\n",
    "    \n",
    "# Definir variables X y y\n",
    "y = data_preparada['PUNT_GLOBAL']\n",
    "X = data_preparada.drop('PUNT_GLOBAL', axis=1)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Añadir una constante (intercepto) al conjunto de entrenamiento\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "# Crear y entrenar el modelo de regresión lineal\n",
    "modelo_lineal = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "# Mostrar el resumen del modelo\n",
    "print(\"\\n--- Resumen del Modelo de Regresión Lineal ---\")\n",
    "print(modelo_lineal.summary())\n",
    "\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "y_pred = modelo_lineal.predict(X_test_sm)\n",
    "\n",
    "# Calcular métricas de desempeño\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Evaluación del Modelo en Datos de Prueba ---\")\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")\n",
    "print(f\"R-cuadrado (R2): {r2:.2f}\")\n",
    "\n",
    "# Conclusiones\n",
    "print(\"\\n--- Hallazgos para el Stakeholder ---\")\n",
    "print(\"El modelo de regresión lineal indica que un subconjunto de variables sociodemográficas sí explica de manera significativa el desempeño de los estudiantes.\")\n",
    "print(\"El R-cuadrado nos dice qué porcentaje de la variabilidad en los puntajes es explicado por el modelo. Un valor positivo y relativamente alto sugiere que las variables de estrato y tipo de colegio son muy relevantes.\")\n",
    "print(\"Los coeficientes del modelo muestran el impacto directo de cada variable. Por ejemplo, un coeficiente positivo para el estrato alto sugiere que a mayor estrato, mayor es el puntaje promedio esperado, lo que resalta las brechas de desigualdad.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUTO-CALIFICADOR COMPLETO DE LA FASE 3\n",
    "\n",
    "# Importaciones necesarias para la validación\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.testing as npt\n",
    "\n",
    "# --- Funciones de validación ---\n",
    "def validar_modelo(modelo, X_train, y_train):\n",
    "    \"\"\"Verifica que el modelo de regresión se haya creado correctamente.\"\"\"\n",
    "    try:\n",
    "        assert isinstance(modelo, sm.regression.linear_model.RegressionResultsWrapper), \"El objeto 'modelo_lineal' no es un modelo de regresión de statsmodels.\"\n",
    "        assert len(modelo.params) == X_train.shape[1] + 1, \"El número de coeficientes del modelo no coincide con las variables de entrada.\"\n",
    "    except AssertionError as e:\n",
    "        raise RuntimeError(f\"Error en la implementación del modelo: {e}\")\n",
    "\n",
    "def validar_metricas(mse, r2):\n",
    "    \"\"\"Verifica que las métricas de evaluación se hayan calculado.\"\"\"\n",
    "    try:\n",
    "        assert isinstance(mse, (int, float, np.float64)), \"La variable 'mse' no es un número.\"\n",
    "        assert isinstance(r2, (int, float, np.float64)), \"La variable 'r2' no es un número.\"\n",
    "        assert mse >= 0, \"El Error Cuadrático Medio (MSE) no puede ser negativo.\"\n",
    "    except AssertionError as e:\n",
    "        raise RuntimeError(f\"Error en el cálculo de métricas: {e}\")\n",
    "\n",
    "# --- Ejecución de la validación ---\n",
    "print(\"\\n--- Ejecutando Autocalificador de la Fase 3 ---\")\n",
    "try:\n",
    "    validar_modelo(modelo_lineal, X_train, y_train)\n",
    "    validar_metricas(mse, r2)\n",
    "    print(\"\\n✅ ¡Fase 3 completada! Tu código de modelado y evaluación pasó todas las pruebas. ¡Excelente trabajo!\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\n❌ Se encontró un error en la validación: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48c276616fb862c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fase 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb30850cd7109d78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Deberás elegir y realizar una de las dos alternativas que se encuentran a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-378e2b071d246af8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Alternativa 1: desarrollar una herramienta interactiva de análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-378e2b071d246af9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase desarrollarás, a partir de alguno de los análisis realizados, una herramienta interactiva que sea relevante en el contexto del problema, acompañada de las instrucciones necesarias para que un usuario la pueda utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-378e2b071d246af10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Seleccionar uno de los análisis previos que pueda verse enriquecido con alguna característica de interactividad.\n",
    "* Seleccionar el/los parámetro(s) que el usuario podrá cambiar.\n",
    "* Desarrollar las funciones que se deben ejecutar con cada acción del usuario.\n",
    "* Utilizar una librería especializada (ej., `ipywidgets`, `panel`, etc.) para implementar la herramienta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-378e2b071d246af11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Cuál o cuáles preguntas podrá hacerle el usuario a la herramienta y cómo aporta la respuesta al análisis?\n",
    "* ¿Qué aprendizajes clave puede explorar u obtener el usuario con esta herramienta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6b287262b7ce28bb",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implementa tu respuesta en esta celda}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8a33682f37a6fa7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Alternativa 2: registrar en bases de datos relacionales con PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8a33682f37a6fa8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase desarrollarás, a partir de alguno de los análisis realizados, un _script_ que sea relevante en el contexto del problema, acompañado de las instrucciones necesarias para que un usuario lo pueda ejecutar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8a33682f37a6fa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Cargar en una base de datos relacional (tipo SQL) el segmento de los datos sobre el cual profundizaste en tu anális, utilizando una tabla distinta para cada categoría de campos. Por ejemplo, una categoría puedes ser información del colegio; en cuyo caso, una tabla debería contener un registro único para cada colegio y todos los campos asociados.\n",
    "\n",
    "* Los campos, a excepción de los identificadores, deben existir en un única tabla.\n",
    "\n",
    "* Cada registro debe existir una única vez en su respectiva tabla.\n",
    "\n",
    "* Cada registro debe tener un identificador único en su tabla, el cual establece una relación entre tablas.\n",
    "\n",
    "* Seleccionar uno de los modelos predictivos implementados.\n",
    "\n",
    "* Crear en la base de datos relacional una tabla que contenga únicamente los identificadores del registro y la predicción de la variable de respuesta hecha por el modelo.\n",
    "\n",
    "* Desarrollar _queries_ de SQL según las siguientes indicaciones y concluir acerca de los resultados:\n",
    "    * Un _query_ que seleccione todos registros y los agregue en una única tabla. Para esto debes relacionar las tablas por su identificador, utilizando el método `JOIN`.\n",
    "    * Un _query_ que contenga el puntaje promedio de los estudiantes, agrupado por año y por colegio.\n",
    "    * Distintos _queries_ que calculen medidas de error de predicción del modelo a partir de los datos reales y las predicciones respectivas. Debes reportar el error para cada registro, el error total de los registros de entrenamiento y el error total de los registros de prueba.\n",
    "    * Haz dos _queries_ adicionales que resulten interesantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8a33682f37a6fa10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Cómo aporta la segmentación de los datos en categorías de campos al manejo de los datos?\n",
    "* ¿Qué filtros y agrupaciones podemos aplicar sobre los datos con el fin de obtener información relevante?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-29052f96082e3438",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implementa tu respuesta en esta celda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32cfb4282f725e3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32cfb4282f725e3c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*  J. VanderPlas (2016) *Python Data Science Handbook: Essential Tools for Working with Data* O'Reilly Media, Inc.\n",
    "*  scikit-learn developers . (2020). Demo of DBSCAN clustering algorithm. 11 Diciembre 2020, de scikit-learn <br> https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#sphx-glr-auto-examples-cluster-plot-dbscan-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32cfb4282f725e3c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Créditos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32cfb4282f725e3c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Autores__: Camilo Hernando Gómez Castro, Alejandro Mantilla Redondo, Jose Fernando Barrera de Plaza, Diego Alejandro Cely Gómez.\n",
    "\n",
    "__Fecha última actualización__: 29/09/2022"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
